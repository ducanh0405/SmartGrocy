{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîß Feature Engineering Guide\n",
        "\n",
        "H∆∞·ªõng d·∫´n chi ti·∫øt v·ªÅ t·ª´ng workstream (WS0-WS6) trong pipeline.\n",
        "\n",
        "## Overview\n",
        "Pipeline bao g·ªìm 7 workstreams:\n",
        "- **WS0**: Aggregation & Master Grid\n",
        "- **WS1**: Relational Features (Product, Household)\n",
        "- **WS2**: Time-Series Features (Lag, Rolling, Calendar)\n",
        "- **WS3**: Behavior Features (Clickstream)\n",
        "- **WS4**: Price & Promotion Features\n",
        "- **WS5**: Stockout Recovery Features\n",
        "- **WS6**: Weather Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-13 01:31:27,254 - src.pipelines._01_load_data - INFO - ======================================================================\n",
            "2025-11-13 01:31:27,255 - src.pipelines._01_load_data - INFO - [PIPELINE STEP 1: LOAD DATA]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-13 01:31:27,256 - src.pipelines._01_load_data - INFO - Active Dataset: FreshRetailNet-50K\n",
            "2025-11-13 01:31:27,256 - src.pipelines._01_load_data - INFO - Data Directory: D:\\datastorm\\E-Grocery_Forecaster\\data\\2_raw\n",
            "2025-11-13 01:31:27,256 - src.pipelines._01_load_data - INFO - ======================================================================\n",
            "2025-11-13 01:31:27,257 - src.pipelines._01_load_data - INFO - Loading FreshRetailNet-50K dataset...\n",
            "2025-11-13 01:31:27,258 - src.pipelines._01_load_data - WARNING -   File not found: sales_hourly.parquet/csv\n",
            "2025-11-13 01:31:27,258 - src.pipelines._01_load_data - INFO -   Loading freshretail_train.parquet...\n",
            "2025-11-13 01:31:30,605 - src.pipelines._01_load_data - INFO - ‚úì Converted 'dt' to 'hour_timestamp'\n",
            "2025-11-13 01:31:30,611 - src.pipelines._01_load_data - INFO - ‚úì Converted 'sale_amount' to 'sales_quantity'\n",
            "2025-11-13 01:31:30,616 - src.pipelines._01_load_data - WARNING -   File not found: stockout_labels.parquet/csv\n",
            "2025-11-13 01:31:30,616 - src.pipelines._01_load_data - WARNING - Stockout labels not found, 'is_stockout' will be 0.\n",
            "2025-11-13 01:31:30,623 - src.pipelines._01_load_data - WARNING -   File not found: weather_data.parquet/csv\n",
            "2025-11-13 01:31:30,624 - src.pipelines._01_load_data - WARNING -   File not found: product_info.parquet/csv\n",
            "2025-11-13 01:31:30,624 - src.pipelines._01_load_data - INFO - Cleaning raw data (handling errors and outliers)...\n",
            "2025-11-13 01:31:31,457 - src.pipelines._01_load_data - INFO - ‚úì Raw data cleaning complete.\n",
            "2025-11-13 01:31:31,458 - src.pipelines._01_load_data - INFO - ‚úÖ Data loading complete. Loaded 3 dataframes: ['sales', 'weather', 'products']\n",
            "Dataset: FreshRetailNet-50K\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.config import setup_project_path, get_dataset_config, setup_logging\n",
        "from src.pipelines._01_load_data import load_data\n",
        "\n",
        "setup_project_path()\n",
        "setup_logging()\n",
        "\n",
        "# Import display for Jupyter notebooks\n",
        "try:\n",
        "    from IPython.display import display\n",
        "except ImportError:\n",
        "    # Fallback if not in Jupyter\n",
        "    display = print\n",
        "\n",
        "# Load data\n",
        "dataframes, config = load_data()\n",
        "print(f\"Dataset: {config['name']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## WS0: Aggregation & Master Grid\n",
        "\n",
        "**M·ª•c ƒë√≠ch**: Chuy·ªÉn ƒë·ªïi transaction-level data th√†nh aggregated weekly/hourly level v√† t·∫°o complete grid.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20880\\2123338363.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mws0_aggregation\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mws0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Get sales data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msales_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sales'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'freshretail_train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mOriginal shape: \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0msales_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Create master grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\datastorm\\E-Grocery_Forecaster\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1575\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1577\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1578\u001b[0m             \u001b[1;33mf\"\u001b[0m\u001b[1;33mThe truth value of a \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m is ambiguous. \u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
          ]
        }
      ],
      "source": [
        "from src.features import ws0_aggregation as ws0\n",
        "\n",
        "# Get sales data\n",
        "sales_df = dataframes.get('sales') or dataframes.get('freshretail_train')\n",
        "print(f\"Original shape: {sales_df.shape}\")\n",
        "\n",
        "# Create master grid\n",
        "master_df = ws0.create_master_grid(sales_df, config)\n",
        "print(f\"Master grid shape: {master_df.shape}\")\n",
        "print(f\"\\nKey columns: {list(master_df.columns[:10])}\")\n",
        "\n",
        "# Show sample\n",
        "display(master_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## WS1: Relational Features\n",
        "\n",
        "**M·ª•c ƒë√≠ch**: Th√™m th√¥ng tin v·ªÅ product v√† household demographics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.features import ws1_relational_features as ws1\n",
        "\n",
        "if config.get('has_relational', False):\n",
        "    master_df = ws1.enrich_relational_features(master_df, dataframes)\n",
        "    print(f\"After WS1 shape: {master_df.shape}\")\n",
        "    \n",
        "    # Show new columns\n",
        "    relational_cols = [col for col in master_df.columns \n",
        "                      if col in ['DEPARTMENT', 'COMMODITY_DESC', 'BRAND', 'MANUFACTURER']]\n",
        "    if relational_cols:\n",
        "        print(f\"\\nRelational columns added: {relational_cols}\")\n",
        "        display(master_df[relational_cols].head())\n",
        "else:\n",
        "    print(\"WS1 skipped: has_relational=False in config\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## WS2: Time-Series Features\n",
        "\n",
        "**M·ª•c ƒë√≠ch**: T·∫°o lag features, rolling statistics, v√† calendar features (LEAK-SAFE).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.features import ws2_timeseries_features as ws2\n",
        "\n",
        "# Add time-series features\n",
        "master_df = ws2.add_lag_rolling_features(master_df, use_config=False)\n",
        "print(f\"After WS2 shape: {master_df.shape}\")\n",
        "\n",
        "# Show time-series features\n",
        "ts_cols = [col for col in master_df.columns \n",
        "          if any(x in col.lower() for x in ['lag', 'rolling', 'week_', 'month_', 'quarter'])]\n",
        "print(f\"\\nTime-series features ({len(ts_cols)}):\")\n",
        "print(ts_cols[:15])\n",
        "\n",
        "# Show sample\n",
        "display(master_df[['PRODUCT_ID', 'STORE_ID', config['time_column'], \n",
        "                   'SALES_VALUE'] + ts_cols[:5]].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## WS4: Price & Promotion Features\n",
        "\n",
        "**M·ª•c ƒë√≠ch**: T√≠nh to√°n price features v√† promotion indicators.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.features import ws4_price_features as ws4\n",
        "\n",
        "# Add price/promotion features\n",
        "master_df = ws4.add_price_promotion_features(master_df, dataframes)\n",
        "print(f\"After WS4 shape: {master_df.shape}\")\n",
        "\n",
        "# Show price/promo features\n",
        "price_cols = [col for col in master_df.columns \n",
        "             if any(x in col.lower() for x in ['price', 'discount', 'promo', 'display', 'mailer'])]\n",
        "print(f\"\\nPrice/Promotion features ({len(price_cols)}):\")\n",
        "print(price_cols)\n",
        "\n",
        "# Show sample\n",
        "if price_cols:\n",
        "    display(master_df[['PRODUCT_ID', 'STORE_ID', 'SALES_VALUE'] + price_cols[:5]].head())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
