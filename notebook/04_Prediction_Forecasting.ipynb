{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìà Prediction & Forecasting\n",
        "\n",
        "S·ª≠ d·ª•ng trained models ƒë·ªÉ t·∫°o forecasts cho t∆∞∆°ng lai.\n",
        "\n",
        "## M·ª•c ti√™u\n",
        "- Load trained quantile models\n",
        "- Prepare future data\n",
        "- Generate predictions v·ªõi uncertainty intervals\n",
        "- Visualize forecasts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'load_models' from 'src.pipelines._05_prediction' (D:\\datastorm\\E-Grocery_Forecaster\\src\\pipelines\\_05_prediction.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(project_root))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_project_path, get_dataset_config, OUTPUT_FILES, setup_logging\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_05_prediction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_models, prepare_prediction_data, make_predictions\n\u001b[0;32m     19\u001b[0m setup_project_path()\n\u001b[0;32m     20\u001b[0m setup_logging()\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_models' from 'src.pipelines._05_prediction' (D:\\datastorm\\E-Grocery_Forecaster\\src\\pipelines\\_05_prediction.py)"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.config import setup_project_path, get_dataset_config, OUTPUT_FILES, setup_logging\n",
        "from src.pipelines._05_prediction import load_models, prepare_prediction_data, make_predictions\n",
        "\n",
        "setup_project_path()\n",
        "setup_logging()\n",
        "\n",
        "# Import display for Jupyter notebooks\n",
        "try:\n",
        "    from IPython.display import display\n",
        "except ImportError:\n",
        "    # Fallback if not in Jupyter\n",
        "    display = print\n",
        "\n",
        "# Get config\n",
        "config = get_dataset_config()\n",
        "print(f\"Dataset: {config['name']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Trained Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load models\n",
        "models_dir = OUTPUT_FILES['models_dir']\n",
        "quantiles = [0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95]\n",
        "\n",
        "models = {}\n",
        "for q in quantiles:\n",
        "    model_file = models_dir / f\"q{int(q*100):02d}_forecaster.joblib\"\n",
        "    if model_file.exists():\n",
        "        models[q] = joblib.load(model_file)\n",
        "        print(f\"‚úÖ Loaded Q{int(q*100):02d} model\")\n",
        "    else:\n",
        "        print(f\"‚ùå Model not found: {model_file}\")\n",
        "\n",
        "print(f\"\\nLoaded {len(models)}/{len(quantiles)} models\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare Future Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load feature table\n",
        "df = pd.read_parquet(OUTPUT_FILES['master_feature_table'])\n",
        "\n",
        "# Get future periods (beyond training data)\n",
        "# Assuming we want to predict next 4 weeks\n",
        "if config['temporal_unit'] == 'week':\n",
        "    max_week = df[config['time_column']].max()\n",
        "    future_weeks = list(range(max_week + 1, max_week + 5))\n",
        "    \n",
        "    # Create future dataframe (simplified - in practice, need to generate features)\n",
        "    print(f\"Current max week: {max_week}\")\n",
        "    print(f\"Future weeks to predict: {future_weeks}\")\n",
        "    print(\"\\nNote: In practice, you need to generate features for future periods\")\n",
        "    print(\"      using the feature engineering pipeline\")\n",
        "else:\n",
        "    print(f\"Temporal unit: {config['temporal_unit']}\")\n",
        "    print(\"Future prediction logic depends on temporal unit\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generate Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use test set for demonstration (in practice, use future data)\n",
        "from src.pipelines._03_model_training import prepare_data\n",
        "\n",
        "_, X_test, _, y_test, features, _ = prepare_data(df, config)\n",
        "\n",
        "# Make predictions for all quantiles\n",
        "predictions = {}\n",
        "for q, model in models.items():\n",
        "    pred = model.predict(X_test[features])\n",
        "    predictions[q] = pred\n",
        "    print(f\"Q{int(q*100):02d} predictions: shape {pred.shape}, mean {pred.mean():.2f}\")\n",
        "\n",
        "# Create prediction dataframe\n",
        "pred_df = pd.DataFrame({\n",
        "    'actual': y_test.values,\n",
        "    **{f'q{int(q*100):02d}': predictions[q] for q in quantiles if q in predictions}\n",
        "})\n",
        "\n",
        "display(pred_df.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot predictions v·ªõi uncertainty intervals\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add uncertainty bands\n",
        "if 0.05 in predictions and 0.95 in predictions:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=list(range(len(pred_df))),\n",
        "        y=pred_df['q95'],\n",
        "        mode='lines',\n",
        "        name='Q95 (Upper)',\n",
        "        line=dict(color='lightblue', width=1),\n",
        "        showlegend=True\n",
        "    ))\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=list(range(len(pred_df))),\n",
        "        y=pred_df['q05'],\n",
        "        mode='lines',\n",
        "        name='Q05 (Lower)',\n",
        "        line=dict(color='lightblue', width=1),\n",
        "        fill='tonexty',\n",
        "        fillcolor='rgba(173, 216, 230, 0.3)',\n",
        "        showlegend=True\n",
        "    ))\n",
        "\n",
        "# Add median prediction\n",
        "if 0.50 in predictions:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=list(range(len(pred_df))),\n",
        "        y=pred_df['q50'],\n",
        "        mode='lines',\n",
        "        name='Q50 (Median)',\n",
        "        line=dict(color='blue', width=2),\n",
        "        showlegend=True\n",
        "    ))\n",
        "\n",
        "# Add actual values\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=list(range(len(pred_df))),\n",
        "    y=pred_df['actual'],\n",
        "    mode='markers',\n",
        "    name='Actual',\n",
        "    marker=dict(color='red', size=4),\n",
        "    showlegend=True\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Quantile Predictions v·ªõi Uncertainty Intervals',\n",
        "    xaxis_title='Sample Index',\n",
        "    yaxis_title='Sales Value',\n",
        "    height=500,\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
