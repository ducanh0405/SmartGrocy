{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc086ec3",
   "metadata": {},
   "source": [
    "# ðŸ“Š Baseline Model - Simple Forecasting Benchmark\n",
    "\n",
    "Táº¡o baseline model Ä‘Æ¡n giáº£n Ä‘á»ƒ benchmark vÃ  so sÃ¡nh vá»›i quantile regression models phá»©c táº¡p.\n",
    "\n",
    "## Má»¥c tiÃªu\n",
    "- Táº¡o simple baseline models (naive, moving average, linear regression)\n",
    "- So sÃ¡nh performance vá»›i quantile models\n",
    "- Hiá»ƒu Ä‘Æ°á»£c improvement tá»« feature engineering vÃ  advanced models\n",
    "\n",
    "## Baseline Models\n",
    "1. **Naive Forecast**: DÃ¹ng giÃ¡ trá»‹ cuá»‘i cÃ¹ng\n",
    "2. **Moving Average**: Trung bÃ¬nh Ä‘á»™ng cá»§a N periods\n",
    "3. **Simple Linear Regression**: Linear trend\n",
    "4. **Seasonal Naive**: DÃ¹ng giÃ¡ trá»‹ cÃ¹ng ká»³ nÄƒm trÆ°á»›c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "736027c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FreshRetailNet-50K\n",
      "Target: sales_quantity\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.config import setup_project_path, get_dataset_config, OUTPUT_FILES, setup_logging\n",
    "from src.pipelines._03_model_training import prepare_data, load_data\n",
    "\n",
    "setup_project_path()\n",
    "setup_logging()\n",
    "\n",
    "# Import display for Jupyter notebooks\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except ImportError:\n",
    "    # Fallback if not in Jupyter\n",
    "    display = print\n",
    "\n",
    "# Get config\n",
    "config = get_dataset_config()\n",
    "print(f\"Dataset: {config['name']}\")\n",
    "print(f\"Target: {config['target_column']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2ac1bd",
   "metadata": {},
   "source": [
    "## 1. Load Data vÃ  Prepare Train/Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc9b17c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-13 01:31:35,950 - src.pipelines._03_model_training - INFO - Loading data from: D:\\datastorm\\E-Grocery_Forecaster\\data\\3_processed\\master_feature_table.parquet...\n",
      "2025-11-13 01:31:35,951 - src.pipelines._03_model_training - ERROR - File not found: D:\\datastorm\\E-Grocery_Forecaster\\data\\3_processed\\master_feature_table.parquet. Run _02_feature_enrichment.py first.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "# Load feature table\n",
    "df = load_data(OUTPUT_FILES['master_feature_table'])\n",
    "print(f\"Feature table shape: {df.shape}\")\n",
    "\n",
    "# Prepare data vá»›i time-based split\n",
    "X_train, X_test, y_train, y_test, features, cat_features = prepare_data(df, config)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Get time column for time-series baselines\n",
    "time_col = config['time_column']\n",
    "target_col = config['target_column']\n",
    "\n",
    "# Create train/test dataframes vá»›i time info\n",
    "train_df = df.loc[X_train.index].copy()\n",
    "test_df = df.loc[X_test.index].copy()\n",
    "\n",
    "train_df['target'] = y_train.values\n",
    "test_df['target'] = y_test.values\n",
    "\n",
    "print(f\"\\nTrain time range: {train_df[time_col].min()} to {train_df[time_col].max()}\")\n",
    "print(f\"Test time range: {test_df[time_col].min()} to {test_df[time_col].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad6bec",
   "metadata": {},
   "source": [
    "## 2. Baseline Model 1: Naive Forecast\n",
    "\n",
    "Dá»± Ä‘oÃ¡n báº±ng giÃ¡ trá»‹ cuá»‘i cÃ¹ng cá»§a má»—i product-store combination.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21976e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive: Use last known value for each product-store\n",
    "def naive_forecast(train_df, test_df, group_cols=None, target='target'):\n",
    "    \"\"\"Naive forecast: last value per group.\"\"\"\n",
    "    # Auto-detect group columns\n",
    "    if group_cols is None:\n",
    "        if 'PRODUCT_ID' in train_df.columns and 'STORE_ID' in train_df.columns:\n",
    "            group_cols = ['PRODUCT_ID', 'STORE_ID']\n",
    "        elif 'product_id' in train_df.columns and 'store_id' in train_df.columns:\n",
    "            group_cols = ['product_id', 'store_id']\n",
    "        else:\n",
    "            raise ValueError(\"Cannot find PRODUCT_ID/STORE_ID columns\")\n",
    "    \n",
    "    # Get last value for each product-store\n",
    "    last_values = train_df.groupby(group_cols)[target].last().reset_index()\n",
    "    last_values.columns = group_cols + ['naive_forecast']\n",
    "    \n",
    "    # Merge vá»›i test set\n",
    "    test_with_forecast = test_df[group_cols + [target]].merge(\n",
    "        last_values, on=group_cols, how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill NaN vá»›i mean (for new product-store combinations)\n",
    "    test_with_forecast['naive_forecast'] = test_with_forecast['naive_forecast'].fillna(\n",
    "        train_df[target].mean()\n",
    "    )\n",
    "    \n",
    "    return test_with_forecast['naive_forecast'].values\n",
    "\n",
    "naive_pred = naive_forecast(train_df, test_df, target='target')\n",
    "\n",
    "# Evaluate\n",
    "naive_mae = mean_absolute_error(y_test, naive_pred)\n",
    "naive_rmse = np.sqrt(mean_squared_error(y_test, naive_pred))\n",
    "\n",
    "print(f\"Naive Forecast:\")\n",
    "print(f\"  MAE: {naive_mae:.4f}\")\n",
    "print(f\"  RMSE: {naive_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6d53d",
   "metadata": {},
   "source": [
    "## 3. Baseline Model 2: Moving Average\n",
    "\n",
    "Dá»± Ä‘oÃ¡n báº±ng trung bÃ¬nh Ä‘á»™ng cá»§a N periods gáº§n nháº¥t.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0399c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Average: Average of last N periods\n",
    "def moving_average_forecast(train_df, test_df, window=4, \n",
    "                           group_cols=None, time_col=None, target='target'):\n",
    "    \"\"\"Moving average forecast: average of last N periods.\"\"\"\n",
    "    # Auto-detect columns\n",
    "    if group_cols is None:\n",
    "        if 'PRODUCT_ID' in train_df.columns and 'STORE_ID' in train_df.columns:\n",
    "            group_cols = ['PRODUCT_ID', 'STORE_ID']\n",
    "        elif 'product_id' in train_df.columns and 'store_id' in train_df.columns:\n",
    "            group_cols = ['product_id', 'store_id']\n",
    "        else:\n",
    "            raise ValueError(\"Cannot find PRODUCT_ID/STORE_ID columns\")\n",
    "    \n",
    "    if time_col is None:\n",
    "        if 'WEEK_NO' in train_df.columns:\n",
    "            time_col = 'WEEK_NO'\n",
    "        elif 'hour_timestamp' in train_df.columns:\n",
    "            time_col = 'hour_timestamp'\n",
    "        elif 'time_column' in config:\n",
    "            time_col = config['time_column']\n",
    "        else:\n",
    "            raise ValueError(\"Cannot find time column\")\n",
    "    \n",
    "    # Calculate moving average for each group\n",
    "    train_sorted = train_df.sort_values(group_cols + [time_col])\n",
    "    train_sorted['ma'] = train_sorted.groupby(group_cols)[target].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "    )\n",
    "    \n",
    "    # Get last MA value for each group\n",
    "    last_ma = train_sorted.groupby(group_cols)['ma'].last().reset_index()\n",
    "    last_ma.columns = group_cols + ['ma_forecast']\n",
    "    \n",
    "    # Merge vá»›i test set\n",
    "    test_with_forecast = test_df[group_cols + [target]].merge(\n",
    "        last_ma, on=group_cols, how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill NaN\n",
    "    test_with_forecast['ma_forecast'] = test_with_forecast['ma_forecast'].fillna(\n",
    "        train_df[target].mean()\n",
    "    )\n",
    "    \n",
    "    return test_with_forecast['ma_forecast'].values\n",
    "\n",
    "ma_pred = moving_average_forecast(train_df, test_df, window=4, target='target')\n",
    "\n",
    "# Evaluate\n",
    "ma_mae = mean_absolute_error(y_test, ma_pred)\n",
    "ma_rmse = np.sqrt(mean_squared_error(y_test, ma_pred))\n",
    "\n",
    "print(f\"Moving Average (window=4):\")\n",
    "print(f\"  MAE: {ma_mae:.4f}\")\n",
    "print(f\"  RMSE: {ma_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad74225",
   "metadata": {},
   "source": [
    "## 4. Baseline Model 3: Simple Linear Regression\n",
    "\n",
    "Dá»± Ä‘oÃ¡n báº±ng linear trend cho má»—i product-store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression: Fit linear trend per group\n",
    "def linear_trend_forecast(train_df, test_df, \n",
    "                         group_cols=None, time_col=None, target='target'):\n",
    "    \"\"\"Linear trend forecast: fit linear regression per group.\"\"\"\n",
    "    # Auto-detect columns\n",
    "    if group_cols is None:\n",
    "        if 'PRODUCT_ID' in train_df.columns and 'STORE_ID' in train_df.columns:\n",
    "            group_cols = ['PRODUCT_ID', 'STORE_ID']\n",
    "        elif 'product_id' in train_df.columns and 'store_id' in train_df.columns:\n",
    "            group_cols = ['product_id', 'store_id']\n",
    "        else:\n",
    "            raise ValueError(\"Cannot find PRODUCT_ID/STORE_ID columns\")\n",
    "    \n",
    "    if time_col is None:\n",
    "        if 'WEEK_NO' in train_df.columns:\n",
    "            time_col = 'WEEK_NO'\n",
    "        elif 'hour_timestamp' in train_df.columns:\n",
    "            time_col = 'hour_timestamp'\n",
    "        elif 'time_column' in config:\n",
    "            time_col = config['time_column']\n",
    "        else:\n",
    "            raise ValueError(\"Cannot find time column\")\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for (prod, store), group_train in train_df.groupby(group_cols):\n",
    "        # Prepare features\n",
    "        X_train_group = group_train[[time_col]].values\n",
    "        y_train_group = group_train[target].values\n",
    "        \n",
    "        # Fit linear model\n",
    "        if len(X_train_group) > 1:\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train_group, y_train_group)\n",
    "            \n",
    "            # Predict for test set\n",
    "            group_test = test_df[(test_df[group_cols[0]] == prod) & \n",
    "                                (test_df[group_cols[1]] == store)]\n",
    "            if len(group_test) > 0:\n",
    "                X_test_group = group_test[[time_col]].values\n",
    "                pred = model.predict(X_test_group)\n",
    "                predictions.extend(pred)\n",
    "            else:\n",
    "                # No test data for this group\n",
    "                pass\n",
    "        else:\n",
    "            # Not enough data, use mean\n",
    "            mean_val = y_train_group[0] if len(y_train_group) > 0 else train_df[target].mean()\n",
    "            group_test = test_df[(test_df[group_cols[0]] == prod) & \n",
    "                                (test_df[group_cols[1]] == store)]\n",
    "            if len(group_test) > 0:\n",
    "                predictions.extend([mean_val] * len(group_test))\n",
    "    \n",
    "    # Handle groups not in training\n",
    "    if len(predictions) < len(test_df):\n",
    "        remaining = len(test_df) - len(predictions)\n",
    "        predictions.extend([train_df[target].mean()] * remaining)\n",
    "    \n",
    "    return np.array(predictions[:len(test_df)])\n",
    "\n",
    "linear_pred = linear_trend_forecast(train_df, test_df, target='target')\n",
    "\n",
    "# Evaluate\n",
    "linear_mae = mean_absolute_error(y_test, linear_pred)\n",
    "linear_rmse = np.sqrt(mean_squared_error(y_test, linear_pred))\n",
    "\n",
    "print(f\"Linear Trend:\")\n",
    "print(f\"  MAE: {linear_mae:.4f}\")\n",
    "print(f\"  RMSE: {linear_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9229c2a3",
   "metadata": {},
   "source": [
    "## 5. Compare All Baselines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all baselines\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Naive', 'Moving Average (4)', 'Linear Trend'],\n",
    "    'MAE': [naive_mae, ma_mae, linear_mae],\n",
    "    'RMSE': [naive_rmse, ma_rmse, linear_rmse]\n",
    "})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BASELINE MODEL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "display(results)\n",
    "\n",
    "# Find best baseline\n",
    "best_idx = results['MAE'].idxmin()\n",
    "print(f\"\\nâœ… Best Baseline: {results.loc[best_idx, 'Model']}\")\n",
    "print(f\"   MAE: {results.loc[best_idx, 'MAE']:.4f}\")\n",
    "print(f\"   RMSE: {results.loc[best_idx, 'RMSE']:.4f}\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig = go.Figure()\n",
    "\n",
    "models = results['Model'].tolist()\n",
    "mae_values = results['MAE'].tolist()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=models,\n",
    "    y=mae_values,\n",
    "    text=[f'{v:.4f}' for v in mae_values],\n",
    "    textposition='auto',\n",
    "    marker_color='lightblue'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Baseline Models Comparison (MAE)',\n",
    "    xaxis_title='Model',\n",
    "    yaxis_title='Mean Absolute Error',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa7357d",
   "metadata": {},
   "source": [
    "## 6. Compare vá»›i Quantile Models (náº¿u Ä‘Ã£ train)\n",
    "\n",
    "So sÃ¡nh baseline vá»›i advanced quantile models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load quantile model metrics náº¿u cÃ³\n",
    "import json\n",
    "metrics_file = OUTPUT_FILES['reports_dir'] / 'metrics' / 'quantile_model_metrics.json'\n",
    "\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, 'r') as f:\n",
    "        quantile_metrics = json.load(f)\n",
    "    \n",
    "    # Get Q50 (median) model MAE (approximate)\n",
    "    q50_pinball = quantile_metrics.get('q50_pinball_loss', None)\n",
    "    \n",
    "    if q50_pinball and 'results' in locals() and 'best_idx' in locals():\n",
    "        print(\"=\" * 70)\n",
    "        print(\"COMPARISON: Baseline vs Quantile Models\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Best Baseline MAE: {results.loc[best_idx, 'MAE']:.4f}\")\n",
    "        print(f\"Q50 Quantile Pinball Loss: {q50_pinball:.4f}\")\n",
    "        print(f\"\\nNote: Pinball loss vÃ  MAE khÃ´ng trá»±c tiáº¿p comparable,\")\n",
    "        print(f\"      nhÆ°ng cÃ³ thá»ƒ tháº¥y improvement tá»« feature engineering\")\n",
    "    elif q50_pinball:\n",
    "        print(\"=\" * 70)\n",
    "        print(\"QUANTILE MODEL METRICS\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Q50 Quantile Pinball Loss: {q50_pinball:.4f}\")\n",
    "        print(\"\\nNote: Run baseline models above to compare\")\n",
    "else:\n",
    "    print(\"Quantile models chÆ°a Ä‘Æ°á»£c train.\")\n",
    "    print(\"Cháº¡y notebook 03_Model_Training.ipynb Ä‘á»ƒ train quantile models trÆ°á»›c.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
