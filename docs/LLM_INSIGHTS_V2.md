# LLM Insights Module V2 - Gemini API Integration

## ğŸ“‹ Tá»•ng quan

Module LLM Insights Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t Ä‘á»ƒ sá»­ dá»¥ng **Gemini API** vá»›i prompt template V2 chuyÃªn nghiá»‡p, cung cáº¥p insights chi tiáº¿t vÃ  actionable cho demand forecasting.

## âœ¨ TÃ­nh nÄƒng má»›i

- âœ… **Prompt V2**: Template chuyÃªn nghiá»‡p vá»›i cáº¥u trÃºc rÃµ rÃ ng
- âœ… **Gemini API Integration**: Sá»­ dá»¥ng Google Gemini Pro lÃ m LLM chÃ­nh
- âœ… **Rule-based Fallback**: Tá»± Ä‘á»™ng fallback náº¿u khÃ´ng cÃ³ API key
- âœ… **Structured Output**: Format chuáº©n vá»›i Executive Summary, Causal Factors, Business Impact, Actions
- âœ… **SHAP Integration**: PhÃ¢n tÃ­ch feature importance tá»« SHAP values

## ğŸ“ Files

### 1. `src/modules/llm_prompts.py` (NEW)
Chá»©a prompt template V2 vá»›i cÃ¡c placeholders:
- Product overview
- Forecast metrics (Q05, Q50, Q95)
- Trend analysis
- SHAP feature importance
- Inventory situation
- Risk assessment

### 2. `src/modules/llm_insights.py` (UPDATED)
Module chÃ­nh vá»›i:
- `LLMInsightGenerator` class
- `_format_prompt()` method Ä‘á»ƒ format prompt V2
- `_call_gemini_api()` method Ä‘á»ƒ gá»i Gemini API
- Rule-based fallback vá»›i helper methods Ä‘áº§y Ä‘á»§

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. Rule-based Mode (KhÃ´ng cáº§n API)

```python
from src.modules.llm_insights import LLMInsightGenerator

generator = LLMInsightGenerator(use_llm_api=False)

forecast_data = {
    'q50': 150,
    'q05': 100,
    'q95': 200,
    'vs_yesterday': 15.5,
    'vs_last_week': 8.2,
    'current_inventory': 120,
    'safety_stock': 30,
    'reorder_point': 100,
    'stockout_risk_pct': 45,
    'overstock_risk_pct': 20,
    'category': 'Fresh Produce',
    'date': '2025-11-16',
    'horizon': '24 hours'
}

shap_data = {
    'promo_active': 0.35,
    'price_change': -0.15,
    'day_of_week': 0.10
}

insight = generator.generate_forecast_insight(
    'P001',
    forecast_data,
    shap_data
)

print(insight['insight_text'])
```

### 2. Gemini API Mode (Cáº§n API key)

#### Setup API Key:

```powershell
# Windows PowerShell
$env:GEMINI_API_KEY="your-api-key-here"

# Hoáº·c táº¡o file .env
echo "GEMINI_API_KEY=your-api-key-here" > .env
```

#### Sá»­ dá»¥ng:

```python
from src.modules.llm_insights import LLMInsightGenerator
import os

# Option 1: Tá»« environment variable
generator = LLMInsightGenerator(
    use_llm_api=True,
    api_provider="gemini",
    model="gemini-2.5-flash"  # Default model
)

# Option 2: Truyá»n trá»±c tiáº¿p
generator = LLMInsightGenerator(
    api_key="your-api-key",
    use_llm_api=True,
    api_provider="gemini",
    model="gemini-2.5-flash"  # or "gemini-2.5-pro" for better quality
)

insight = generator.generate_forecast_insight(
    'P001',
    forecast_data,
    shap_data,
    use_llm=True  # Force LLM mode
)

print(insight['insight_text'])
```

### 3. Convenience Function

```python
from src.modules.llm_insights import generate_insight

insight_text = generate_insight(
    'P001',
    forecast_data,
    shap_data,
    use_llm=True,
    api_key="your-key",
    api_provider="gemini"
)
# Note: Default model is "gemini-2.5-flash"

print(insight_text)
```

## ğŸ“Š Output Format

### Rule-based Output:

```
## ğŸ“Š EXECUTIVE SUMMARY

Demand forecast for this product is showing **moderate growth** (+16%) 
with **moderate uncertainty**. Expected demand: **150 units**. 
inventory levels are manageable.

## ğŸ” CAUSAL FACTORS

1. **Active Promotion** (35.0% impact)
   - Active promotional campaign driving sales
2. **Yesterday's Demand** (25.0% impact)
   - Yesterday's demand was higher than usual, boosting today's forecast

## ğŸ“ˆ BUSINESS IMPACT

- **Inventory Status**: Below forecast level (80.0%)
- **Stockout Risk**: MODERATE (45%) - Monitor closely

## âœ… RECOMMENDED ACTIONS

1. **ğŸ‘ï¸ ONGOING - Monitor Key Indicators**
   - Track hourly sales vs forecast
   - Alert if actual demand deviates >20% from Q50
```

### LLM Output (Gemini):

Gemini sáº½ táº¡o insights chi tiáº¿t hÆ¡n vá»›i:
- Executive Summary (2-3 cÃ¢u)
- Causal Explanation (3-4 bullet points)
- Business Impact Assessment
- Recommended Actions (Priority-ordered)
- Risk Mitigation (náº¿u cáº§n)

## ğŸ”§ Configuration

### InsightConfig Parameters:

- `use_llm_api`: `bool` - Báº­t/táº¯t LLM API
- `api_provider`: `str` - "gemini", "openai", "anthropic"
- `api_key`: `str` - API key (optional, cÃ³ thá»ƒ dÃ¹ng env var)
- `model`: `str` - Model name (default: "gemini-2.5-flash")

### Supported Models:

**Gemini:**
- `gemini-2.5-flash` (recommended - fast and cost-effective)
- `gemini-2.5-pro` (better quality, slower)
- `gemini-pro-latest` (backward compatible)

**OpenAI (fallback):**
- `gpt-4`
- `gpt-3.5-turbo`

**Anthropic (fallback):**
- `claude-3-opus`
- `claude-3-sonnet`

## ğŸ“ Forecast Data Structure

```python
forecast_data = {
    # Required
    'q50': float,              # Median forecast
    'q05': float,              # Pessimistic case
    'q95': float,              # Optimistic case
    
    # Optional but recommended
    'vs_yesterday': float,      # % change vs yesterday
    'vs_last_week': float,      # % change vs last week
    'vs_monthly_avg': float,    # % change vs monthly avg
    
    # Inventory metrics
    'current_inventory': float,
    'safety_stock': float,
    'reorder_point': float,
    'stockout_risk_pct': float,  # 0-100
    'overstock_risk_pct': float, # 0-100
    
    # Metadata
    'category': str,
    'date': str,                # YYYY-MM-DD
    'horizon': str              # e.g., "24 hours"
}
```

## ğŸ§ª Testing

### Test Rule-based:

```bash
python scripts/test_llm_insights_v2.py
```

### Test vá»›i Gemini API:

```powershell
# Set API key
$env:GEMINI_API_KEY="your-key"

# Run test
python scripts/test_llm_insights_v2.py
```

## ğŸ”„ Migration tá»« Version cÅ©

Náº¿u báº¡n Ä‘ang dÃ¹ng version cÅ©:

1. **Import path khÃ´ng Ä‘á»•i**: `from src.modules.llm_insights import LLMInsightGenerator`
2. **API thay Ä‘á»•i**: 
   - CÅ©: `InsightConfig(use_llm_api=True, api_provider="openai")`
   - Má»›i: `LLMInsightGenerator(use_llm_api=True, api_provider="gemini")`
3. **Prompt tá»± Ä‘á»™ng**: Prompt V2 Ä‘Æ°á»£c sá»­ dá»¥ng tá»± Ä‘á»™ng khi cÃ³ `llm_prompts.py`

## âš ï¸ LÆ°u Ã½

1. **API Key Security**: 
   - KhÃ´ng commit API key vÃ o Git
   - Sá»­ dá»¥ng environment variables
   - ThÃªm `.env` vÃ o `.gitignore`

2. **Fallback Behavior**:
   - Náº¿u khÃ´ng cÃ³ API key â†’ tá»± Ä‘á»™ng dÃ¹ng rule-based
   - Náº¿u API call fail â†’ tá»± Ä‘á»™ng fallback vá» rule-based

3. **Cost Management**:
   - Gemini API cÃ³ free tier (generous)
   - Monitor usage trong Google Cloud Console
   - Rule-based mode hoÃ n toÃ n free

4. **Encoding Issues**:
   - Windows console cÃ³ thá»ƒ khÃ´ng hiá»ƒn thá»‹ emoji
   - Code Ä‘Ã£ xá»­ lÃ½ fallback tá»± Ä‘á»™ng

## ğŸ“š Examples

Xem thÃªm examples trong:
- `scripts/test_llm_insights_v2.py`
- `scripts/test_gemini_insights.py` (náº¿u cÃ³)

## ğŸ†˜ Troubleshooting

### Lá»—i: "No API key found"
â†’ Set environment variable: `$env:GEMINI_API_KEY="your-key"`

### Lá»—i: "google-generativeai not installed"
â†’ Install: `pip install google-generativeai`

### Lá»—i: "UnicodeEncodeError"
â†’ ÄÃ£ Ä‘Æ°á»£c xá»­ lÃ½ tá»± Ä‘á»™ng, náº¿u váº«n lá»—i thÃ¬ check console encoding

### LLM khÃ´ng hoáº¡t Ä‘á»™ng
â†’ Check API key, network connection, hoáº·c dÃ¹ng rule-based mode

---

**Version**: 1.0.0  
**Last Updated**: 2025-11-16  
**Author**: SmartGrocy Team

