import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score
import warnings
import time
import sys
import joblib
import json
from pathlib import Path 

# === XÃC Äá»ŠNH ÄÆ¯á»œNG DáºªN Gá»C ===
# (file -> pipelines -> src -> E-Grocery_Forecaster)
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
# ===============================

warnings.filterwarnings('ignore')

# -----------------------------------------------------------------
# 1. Cáº¤U HÃŒNH Dá»° ÃN (ÄÃƒ TÃCH Há»¢P)
# -----------------------------------------------------------------
CONFIG = {
    # 1. File Ä‘áº§u vÃ o (tá»« pipeline xá»­ lÃ½ dá»¯ liá»‡u)
    # Äá»c file Parquet (Ä‘áº§u ra cá»§a _02_feature_enrichment.py)
    "data_file": PROJECT_ROOT / 'data' / '3_processed' / 'master_feature_table.parquet',

    # 2. Files Ä‘áº§u ra (lÆ°u vÃ o thÆ° má»¥c 'models' vÃ  'reports')
    "model_output_path": PROJECT_ROOT / 'models' / 'final_forecaster.joblib',
    "features_output_path": PROJECT_ROOT / 'models' / 'model_features.json',
    "metrics_output_path": PROJECT_ROOT / 'reports' / 'metrics' / 'final_model_metrics.json',

    "tuning_iterations": 25,
    "cv_folds": 3
}

# -----------------------------------------------------------------
# 2. CÃC HÃ€M CHá»¨C NÄ‚NG (ÄÃƒ ÄIá»€N Äáº¦Y Äá»¦)
# -----------------------------------------------------------------

def load_data(filepath):
    """Táº£i dá»¯ liá»‡u sáº¡ch tá»« pipeline."""
    print(f"[HÃ m load_data] Äang táº£i dá»¯ liá»‡u tá»«: {filepath}...")
    start_time = time.time()
    try:
        # Chuyá»ƒn Path object sang string Ä‘á»ƒ dÃ¹ng .endswith()
        if str(filepath).endswith('.parquet'):
            df = pd.read_parquet(filepath)
        elif str(filepath).endswith('.csv'):
            df = pd.read_csv(filepath)
        else:
            raise ValueError(f"Äá»‹nh dáº¡ng file khÃ´ng Ä‘Æ°á»£c há»— trá»£: {filepath}")
            
        print(f"âœ“ Táº£i xong. Shape: {df.shape}. (Máº¥t {time.time() - start_time:.2f}s)")
        return df
    except FileNotFoundError:
        print(f"ğŸš¨ Lá»–I: KhÃ´ng tÃ¬m tháº¥y file {filepath}.")
        print("Vui lÃ²ng cháº¡y pipeline xá»­ lÃ½ dá»¯ liá»‡u (_02_feature_enrichment.py) trÆ°á»›c.")
        sys.exit(1)
    except Exception as e:
        print(f"ğŸš¨ Lá»–I khi táº£i file: {e}")
        sys.exit(1)


def prepare_data(df):
    """
    Lá»c, táº¡o biáº¿n má»¥c tiÃªu (is_good_review), chá»n Ä‘áº·c trÆ°ng (CHá»ˆ WS1), 
    vÃ  chia dá»¯ liá»‡u.
    """
    print("[HÃ m prepare_data] Äang chuáº©n bá»‹ dá»¯ liá»‡u...")

    # Logic lá»c (Giáº£ sá»­ báº¡n Ä‘ang dá»± Ä‘oÃ¡n 'is_good_review' tá»« WS1)
    if 'review_score' not in df.columns:
        print("ğŸš¨ Lá»–I: Thiáº¿u cá»™t 'review_score' trong file Ä‘Ã£ xá»­ lÃ½.")
        sys.exit(1)
        
    # TÃ¬m cá»™t tráº¡ng thÃ¡i Ä‘Æ¡n hÃ ng (Æ°u tiÃªn 'order_status')
    if 'order_status' in df.columns:
        df_model = df[(df['order_status'] == 'delivered') & (df['review_score'] > 0)].copy()
    elif 'delivery_time_days' in df.columns:
         df_model = df[(df['delivery_time_days'] > -999) & (df['review_score'] > 0)].copy()
    else:
        print("ğŸš¨ Lá»–I: KhÃ´ng tÃ¬m tháº¥y cá»™t 'order_status' hoáº·c 'delivery_time_days' Ä‘á»ƒ lá»c dá»¯ liá»‡u.")
        sys.exit(1)

    if df_model.empty:
        print("ğŸš¨ Lá»–I: KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u Ä‘Ã£ giao vÃ  Ä‘Ã£ review Ä‘á»ƒ huáº¥n luyá»‡n.")
        sys.exit(1)

    # Táº¡o biáº¿n má»¥c tiÃªu (Y)
    target_col = 'is_good_review'
    df_model[target_col] = (df_model['review_score'] == 5).astype(int)
    print(f"PhÃ¢n bá»• biáº¿n má»¥c tiÃªu (Y = is_good_review):")
    print(df_model[target_col].value_counts(normalize=True).apply(lambda x: f"{x:.1%}"))

    # === CHá»ˆ Sá»¬ Dá»¤NG Äáº¶C TRÆ¯NG WS1 (OLIST) ===
    numeric_features = [
        # --- Äáº·c trÆ°ng WS1 (Olist PoC) ---
        'delivery_time_days', 'delivery_vs_estimated_days', 'order_processing_time_days',
        'price', 'freight_value', 'freight_ratio', 'payment_value_total',
        'payment_installments_total', 'payment_sequential_count', 'dist_cust_seller_km',
        'product_weight_g', 'product_volume_cm3', 'purchase_day_of_week', 'purchase_hour',
        
        # --- Äáº¶C TRÆ¯NG Má»šI Tá»ª WORKSTREAM 3 (BEHAVIOR) ---
        # (ChÃºng ta sáº½ táº¡m thá»i comment cÃ¡c dÃ²ng nÃ y láº¡i)
        # 'total_views',
        # 'total_addtocart',
        # 'total_transactions',
        # 'rate_view_to_cart',
        # 'rate_cart_to_buy',
        # 'rate_view_to_buy',
        # 'session_duration_days',
        # 'days_since_last_action'
    ]
    
    categorical_features = [
        # --- Äáº·c trÆ°ng WS1 (Olist PoC) ---
        'product_category_name_english', 'customer_state', 'seller_state',
        'payment_type_primary', 'is_weekend'
    ]
    # === Káº¾T THÃšC CHá»ˆNH Sá»¬A ===

    all_features = [col for col in (numeric_features + categorical_features) if col in df.columns]
    categorical_features = [col for col in categorical_features if col in all_features]
    
    missing_features = set(numeric_features + categorical_features) - set(df.columns)
    if missing_features:
        print(f"âš ï¸ Cáº£nh bÃ¡o: Thiáº¿u cÃ¡c Ä‘áº·c trÆ°ng sau: {missing_features}")

    if not all_features:
        print("ğŸš¨ Lá»–I: KhÃ´ng tÃ¬m tháº¥y báº¥t ká»³ Ä‘áº·c trÆ°ng nÃ o trong file.")
        sys.exit(1)
        
    print(f"TÃ¬m tháº¥y {len(all_features)} Ä‘áº·c trÆ°ng há»£p lá»‡ (WS1) Ä‘á»ƒ huáº¥n luyá»‡n.")

    X = df_model[all_features]
    y = df_model[target_col]

    # Chuyá»ƒn Ä‘á»•i dtype cho LightGBM
    print(f"Äang chuyá»ƒn Ä‘á»•i {len(categorical_features)} cá»™t sang 'category' dtype...")
    for col in categorical_features:
        X[col] = X[col].astype('category')

    # Chia Train/Test
    print("Äang chia Train/Test (80/20)...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=0.2, 
        random_state=42, 
        stratify=y
    )
    print("âœ“ Chuáº©n bá»‹ dá»¯ liá»‡u hoÃ n táº¥t.")

    return X_train, X_test, y_train, y_test, all_features, categorical_features


def tune_model(X_train, y_train, categorical_features):
    """Tinh chá»‰nh hyperparameters báº±ng RandomizedSearchCV."""
    print("[HÃ m tune_model] Báº¯t Ä‘áº§u tinh chá»‰nh siÃªu tham sá»‘...")
    start_train = time.time()

    try:
        scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
        print(f"Máº¥t cÃ¢n báº±ng: Tá»· lá»‡ (Xáº¥u/Tá»‘t) lÃ  {scale_pos_weight:.2f}")
    except ZeroDivisionError:
        scale_pos_weight = 1

    param_grid = {
        'n_estimators': [200, 500, 1000, 1500],
        'learning_rate': [0.01, 0.02, 0.05, 0.1],
        'num_leaves': [20, 31, 40, 50],
        'max_depth': [-1, 10, 15, 20],
        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
        'subsample': [0.7, 0.8, 0.9, 1.0],
        'reg_alpha': [0, 0.1, 0.5],
        'reg_lambda': [0, 0.1, 0.5]
    }

    kfold = StratifiedKFold(n_splits=CONFIG['cv_folds'], shuffle=True, random_state=42)

    base_model = lgb.LGBMClassifier(
        random_state=42,
        scale_pos_weight=scale_pos_weight,
        n_jobs=-1
    )

    random_search = RandomizedSearchCV(
        estimator=base_model,
        param_distributions=param_grid,
        n_iter=CONFIG['tuning_iterations'],
        cv=kfold,
        scoring='roc_auc',
        n_jobs=-1,
        random_state=42,
        verbose=1
    )

    random_search.fit(
        X_train,
        y_train,
        categorical_feature=categorical_features
    )

    print(f"\nâœ“ Tinh chá»‰nh hoÃ n táº¥t (Máº¥t {time.time() - start_train:.2f}s)")
    print("\n" + "=" * 50)
    print("           MÃ” HÃŒNH Tá»I Æ¯U NHáº¤T ÄÃƒ TÃŒM THáº¤Y")
    print("=" * 50)
    print(f"Äiá»ƒm (ROC AUC) tá»‘t nháº¥t: {random_search.best_score_:.4f}")
    print("CÃ¡c tham sá»‘ tá»‘t nháº¥t:")
    print(random_search.best_params_)
    print("=" * 50)

    return random_search.best_estimator_


def evaluate_model(model, X_test, y_test):
    """ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh cuá»‘i cÃ¹ng trÃªn táº­p Test vÃ  tráº£ vá» dict metrics."""
    print("[HÃ m evaluate_model] Äang Ä‘Ã¡nh giÃ¡ trÃªn táº­p Test...")
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    accuracy = accuracy_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    report_dict = classification_report(y_test, y_pred, target_names=['Bad (0)', 'Good (1)'], output_dict=True)
    report_str = classification_report(y_test, y_pred, target_names=['Bad (0)', 'Good (1)'])
    cm = confusion_matrix(y_test, y_pred)

    print("\n" + "=" * 50)
    print("      Káº¾T QUáº¢ ÄÃNH GIÃ MÃ” HÃŒNH (TRÃŠN Táº¬P TEST)")
    print("=" * 50)
    print(f"ğŸ¯ Accuracy (Äá»™ chÃ­nh xÃ¡c): {accuracy:.2%}")
    print(f"ğŸ¯ ROC AUC: {roc_auc:.4f}")
    print("\nğŸ“Š BÃ¡o cÃ¡o PhÃ¢n loáº¡i:")
    print(report_str)
    print("\nğŸ”¢ Ma tráº­n nháº§m láº«n:")
    print(pd.DataFrame(cm, index=['Actual: Bad', 'Actual: Good'], columns=['Predicted: Bad', 'Predicted: Good']))
    print("=" * 50)

    metrics = {
        "accuracy": accuracy,
        "roc_auc": roc_auc,
        "classification_report": report_dict,
        "confusion_matrix": cm.tolist()
    }
    return metrics


def save_artifacts(model, features_config, metrics):
    """LÆ°u mÃ´ hÃ¬nh, danh sÃ¡ch Ä‘áº·c trÆ°ng, vÃ  metrics ra file."""
    print("[HÃ m save_artifacts] Äang lÆ°u cÃ¡c 'artifacts' cá»§a mÃ´ hÃ¬nh...")

    # Tá»± Ä‘á»™ng táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
    (PROJECT_ROOT / 'models').mkdir(parents=True, exist_ok=True)
    (PROJECT_ROOT / 'reports' / 'metrics').mkdir(parents=True, exist_ok=True)

    # 1. LÆ°u mÃ´ hÃ¬nh
    try:
        joblib.dump(model, CONFIG['model_output_path'])
        print(f"âœ“ MÃ´ hÃ¬nh Ä‘Ã£ lÆ°u táº¡i: {CONFIG['model_output_path']}")
    except Exception as e:
        print(f"ğŸš¨ Lá»–I khi lÆ°u mÃ´ hÃ¬nh: {e}")

    # 2. LÆ°u cáº¥u hÃ¬nh Ä‘áº·c trÆ°ng
    try:
        with open(CONFIG['features_output_path'], 'w') as f:
            json.dump(features_config, f, indent=4)
        print(f"âœ“ Cáº¥u hÃ¬nh Ä‘áº·c trÆ°ng Ä‘Ã£ lÆ°u táº¡i: {CONFIG['features_output_path']}")
    except Exception as e:
        print(f"ğŸš¨ Lá»–I khi lÆ°u file features: {e}")

    # 3. LÆ°u metrics
    try:
        with open(CONFIG['metrics_output_path'], 'w') as f:
            json.dump(metrics, f, indent=4)
        print(f"âœ“ Metrics Ä‘Ã£ lÆ°u táº¡i: {CONFIG['metrics_output_path']}")
    except Exception as e:
        print(f"ğŸš¨ Lá»–I khi lÆ°u file metrics: {e}")


# -----------------------------------------------------------------
# 3. HÃ€M CHÃNH (MAIN ORCHESTRATOR)
# -----------------------------------------------------------------

def main():
    """Äiá»u phá»‘i toÃ n bá»™ quy trÃ¬nh huáº¥n luyá»‡n."""
    print("========== Báº®T Äáº¦U QUY TRÃŒNH HUáº¤N LUYá»†N MÃ” HÃŒNH (WS1 OLIST) ==========")
    total_start_time = time.time()

    # BÆ¯á»šC 1: Táº£i dá»¯ liá»‡u
    print("\n--- BÆ¯á»šC 1: Táº¢I Dá»® LIá»†U ---")
    df = load_data(CONFIG['data_file'])

    # BÆ¯á»šC 2: Chuáº©n bá»‹ dá»¯ liá»‡u
    print("\n--- BÆ¯á»šC 2: CHUáº¨N Bá»Š Dá»® LIá»†U & CHIA Táº¬P ---")
    X_train, X_test, y_train, y_test, features, cat_features = prepare_data(df)

    # BÆ¯á»šC 3: Tinh chá»‰nh (Tune) mÃ´ hÃ¬nh
    print("\n--- BÆ¯á»šC 3: TINH CHá»ˆNH MÃ” HÃŒNH (TUNING) ---")
    best_model = tune_model(X_train, y_train, cat_features)

    # BÆ¯á»šC 4: ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh tá»‘t nháº¥t
    print("\n--- BÆ¯á»šC 4: ÄÃNH GIÃ MÃ” HÃŒNH CUá»I CÃ™NG ---")
    metrics = evaluate_model(best_model, X_test, y_test)

    # BÆ¯á»šC 5: LÆ°u "Artifacts"
    print("\n--- BÆ¯á»šC 5: LÆ¯U ARTIFACTS (MÃ” HÃŒNH, FEATURES, METRICS) ---")
    features_config = {
        "all_features": features,
        "categorical_features": cat_features
    }
    save_artifacts(best_model, features_config, metrics)

    print("\n========================================================")
    print(f"ğŸ¥³ HOÃ€N THÃ€NH! Tá»•ng thá»i gian cháº¡y: {time.time() - total_start_time:.2f} giÃ¢y.")
    print(f"CÃ¡c file káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {CONFIG['model_output_path']} vÃ  cÃ¡c file .json liÃªn quan.")
    print("========================================================")


# --- ÄIá»‚M Báº®T Äáº¦U CHáº Y SCRIPT ---
if __name__ == "__main__":
    main()