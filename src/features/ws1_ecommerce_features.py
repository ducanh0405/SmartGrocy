import pandas as pd
import numpy as np
import logging
from haversine import haversine

def aggregate_payments(df_payments):
    """(WS1 PoC) Gá»™p báº£ng payments."""
    logging.info("[WS1] Äang gá»™p (Aggregate) báº£ng 'payments'...")
    df_payments_agg = df_payments.groupby('order_id').agg(
        payment_installments_total=('payment_installments', 'sum'),
        payment_value_total=('payment_value', 'sum'),
        payment_type_primary=('payment_type', 'first'),
        payment_sequential_count=('payment_sequential', 'max')
    ).reset_index()
    return df_payments_agg

def aggregate_geolocation(df_geo):
    """(WS1 PoC) Aggregate geolocation Ä‘á»ƒ tá»‘i Æ°u merge."""
    logging.info("[WS1] Äang gá»™p (Aggregate) báº£ng 'geolocation'...")
    df_geo_agg = df_geo.groupby('geolocation_zip_code_prefix').agg(
        geo_lat=('geolocation_lat', 'mean'),
        geo_lng=('geolocation_lng', 'mean')
    ).reset_index()
    return df_geo_agg

def merge_tables(dataframes, df_payments_agg, df_geo_agg):
    """(WS1 PoC) Thá»±c thi pipeline há»£p nháº¥t (merge) cÃ¡c báº£ng Olist."""
    logging.info("[WS1] Äang há»£p nháº¥t (Merge) cÃ¡c báº£ng Olist...")
    df_master = dataframes['orders'].copy()

    # Merge báº£ng chÃ­nh
    df_master = pd.merge(df_master, dataframes['customers'], on='customer_id', how='left')
    df_reviews_dedup = dataframes['reviews'].sort_values('review_creation_date', ascending=False).drop_duplicates('order_id', keep='first')
    df_master = pd.merge(df_master, df_reviews_dedup, on='order_id', how='left')
    df_master = pd.merge(df_master, df_payments_agg, on='order_id', how='left')
    df_master = pd.merge(df_master, dataframes['order_items'], on='order_id', how='left')
    df_master = pd.merge(df_master, dataframes['products'], on='product_id', how='left')
    df_master = pd.merge(df_master, dataframes['sellers'], on='seller_id', how='left')
    # Merge geolocation features for customer
    df_master = pd.merge(
        df_master, 
        df_geo_agg, 
        left_on='customer_zip_code_prefix', 
        right_on='geolocation_zip_code_prefix', 
        how='left', 
        suffixes=('', '_customer')
    )
    # Rename customer lat/lng fields for clarity
    df_master = df_master.rename(columns={
        'geo_lat': 'customer_lat',
        'geo_lng': 'customer_lng'
    })
    # Merge geolocation features for seller
    df_master = pd.merge(
        df_master, 
        df_geo_agg, 
        left_on='seller_zip_code_prefix', 
        right_on='geolocation_zip_code_prefix', 
        how='left', 
        suffixes=('', '_seller')
    )
    df_master = df_master.rename(columns={
        'geo_lat': 'seller_lat',
        'geo_lng': 'seller_lng'
    })
    logging.info(f"-> Há»£p nháº¥t (Merge) WS1 thÃ nh cÃ´ng. Shape: {df_master.shape}")
    return df_master

def create_features(df_merged):
    """(WS1 PoC) Táº¡o táº¥t cáº£ cÃ¡c Ä‘áº·c trÆ°ng nghiá»‡p vá»¥ Olist."""
    logging.info("[WS1] Äang táº¡o Ä‘áº·c trÆ°ng Olist (Feature Engineering)...")
    df_featured = df_merged.copy()

    # 1. Chuyá»ƒn Ä‘á»•i Thá»i gian
    time_cols = ['order_purchase_timestamp', 'order_approved_at', ...]
    # ... (Copy toÃ n bá»™ logic tá»« hÃ m create_features cá»§a báº¡n) ...
    
    # 2. Äáº·c trÆ°ng Váº­n hÃ nh
    df_featured['delivery_time_days'] = ...
    
    # 4. Äáº·c trÆ°ng Äá»‹a lÃ½ (Khoáº£ng cÃ¡ch)
    locations_available = df_featured[['customer_lat', ...]].notnull().all(axis=1)
    # ...
    
    logging.info(f"-> Táº¡o Ä‘áº·c trÆ°ng WS1 hoÃ n táº¥t. Shape: {df_featured.shape}")
    return df_featured

def clean_and_impute(df_featured):
    """(WS1 PoC) LÃ m sáº¡ch vÃ  Ä‘iá»n Nulls cuá»‘i cÃ¹ng cho Olist."""
    logging.info("[WS1] Äang thá»±c hiá»‡n lÃ m sáº¡ch cuá»‘i cÃ¹ng (Clean & Impute)...")
    df_clean = df_featured.copy()

    # === 1. LÃ€M Sáº CH (Cleaning) ===
    # ... (Copy toÃ n bá»™ logic tá»« hÃ m clean_and_impute cá»§a báº¡n) ...
    
    # === 2. ÄIá»€N NULLS (Imputation) ===
    # 2.1 Cá»™t Review Score (0 = ChÆ°a review)
    df_clean['review_score'] = df_clean['review_score'].fillna(0)
    
    # 2.2 Cá»™t Váº­n hÃ nh (ChÆ°a giao = -999)
    delivery_cols_to_flag = ['delivery_time_days', ...]
    # ...
    
    # 3. LÃ m sáº¡ch cuá»‘i cÃ¹ng (loáº¡i bá» hÃ ng thiáº¿u khÃ³a chÃ­nh)
    df_clean.dropna(subset=['order_id', 'order_item_id'], inplace=True)

    logging.info("-> LÃ m sáº¡ch cuá»‘i cÃ¹ng WS1 hoÃ n táº¥t.")
    return df_clean

def load_olist_data(data_dir):
    """(WS1 PoC) Táº£i 9 tá»‡p Olist."""
    logging.info(f"[WS1] Äang táº£i dá»¯ liá»‡u PoC Olist tá»«: {data_dir}...")
    files_to_keys = {
        'olist_orders_dataset.csv': 'orders', 
        # ... (Copy toÃ n bá»™ logic tá»« hÃ m load_data cá»§a báº¡n) ...
    }
    dataframes = {}
    try:
        for file, key in files_to_keys.items():
            file_path = os.path.join(data_dir, file)
            dataframes[key] = pd.read_csv(file_path)
        logging.info(f"-> Táº£i {len(dataframes)} tá»‡p Olist thÃ nh cÃ´ng.")
        return dataframes
    except FileNotFoundError as e:
        logging.error(f"ğŸš¨ Lá»–I (WS1): KhÃ´ng tÃ¬m tháº¥y file {e.filename}.")
        sys.exit(1)